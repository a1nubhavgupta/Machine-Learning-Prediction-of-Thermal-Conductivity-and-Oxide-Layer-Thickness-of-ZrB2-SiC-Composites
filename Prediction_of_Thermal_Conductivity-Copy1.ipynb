{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac3e4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pointbiserialr\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/__init__.py:626\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    625\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_stats_py.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, _get_nan,\n\u001b[1;32m     44\u001b[0m                               _rename_parameter, _contains_nan,\n\u001b[1;32m     45\u001b[0m                               normalize_axis_index, np_vecdot, AxisError)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/spatial/__init__.py:116\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plotutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_procrustes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m procrustes\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_geometric_slerp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geometric_slerp\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ckdtree, kdtree, qhull\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/spatial/_geometric_slerp.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m euclidean\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/spatial/distance.py:121\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecated\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rel_entr\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _hausdorff, _distance_pybind, _distance_wrap\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_copy_array_if_base_present\u001b[39m(a):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/special/__init__.py:790\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;66;03m# Replace some function definitions from _ufuncs to add Array API support\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_support_alternative_backends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 790\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _basic\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logsumexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, softmax, log_softmax\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/special/_basic.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _specfun\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_comb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _comb_int\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (assoc_legendre_p_all,\n\u001b[1;32m     23\u001b[0m                            legendre_p_all)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecated\n\u001b[1;32m     27\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai_zeros\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massoc_laguerre\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeta\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     88\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/special/_multiufuncs.py:142\u001b[0m\n\u001b[1;32m    137\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_out(out)\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 142\u001b[0m sph_legendre_p \u001b[38;5;241m=\u001b[39m MultiUFunc(\n\u001b[1;32m    143\u001b[0m     sph_legendre_p,\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"sph_legendre_p(n, m, theta, *, diff_n=0)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Spherical Legendre polynomial of the first kind.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    n : ArrayLike[int]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m        Degree of the spherical Legendre polynomial. Must have ``n >= 0``.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    m : ArrayLike[int]\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m        Order of the spherical Legendre polynomial.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    theta : ArrayLike[float]\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m        Input value.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    diff_n : Optional[int]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m        A non-negative integer. Compute and return all derivatives up\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m        to order ``diff_n``. Default is 0.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    p : ndarray or tuple[ndarray]\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m        Spherical Legendre polynomial with ``diff_n`` derivatives.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    The spherical counterpart of an (unnormalized) associated Legendre polynomial has\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    the additional factor\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m        \\sqrt{\\frac{(2 n + 1) (n - m)!}{4 \\pi (n + m)!}}\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    It is the same as the spherical harmonic :math:`Y_{n}^{m}(\\theta, \\phi)`\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    with :math:`\\phi = 0`.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m, diff_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    177\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;129m@sph_legendre_p\u001b[39m\u001b[38;5;241m.\u001b[39m_override_key\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(diff_n):\n\u001b[1;32m    182\u001b[0m     diff_n \u001b[38;5;241m=\u001b[39m _nonneg_int_or_fail(diff_n, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/special/_multiufuncs.py:41\u001b[0m, in \u001b[0;36mMultiUFunc.__init__\u001b[0;34m(self, ufunc_or_ufuncs, doc, force_complex_output, **default_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ufunc \u001b[38;5;129;01min\u001b[39;00m ufuncs_iter:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ufunc, np\u001b[38;5;241m.\u001b[39mufunc):\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll ufuncs must have type `numpy.ufunc`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mufunc_or_ufuncs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     seen_input_types\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mfrozenset\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m->\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mtypes))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seen_input_types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_absolute_percentage_error,mean_squared_error,mean_absolute_percentage_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer,RobustScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,StratifiedKFold,LeaveOneOut,LeavePOut,validation_curve,learning_curve\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,VotingRegressor,StackingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# from xgboost import XGBRegressor,XGBRFRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge,ARDRegression,Lasso, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5992cb5",
   "metadata": {},
   "source": [
    "## Cleaning the dataset for Thermal Conductivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('sample10.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b767700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove 'Sinter Method' column and row before calculating correlation matrix\n",
    "df_filtered = df_raw.drop(columns=['Sinter method'], errors='ignore')\n",
    "corr_matrix = df_filtered.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Rename specific labels with bold, subscripts, and Greek letters using LaTeX formatting\n",
    "corr_matrix = corr_matrix.rename(\n",
    "    index={'Relative Density': r'$\\mathbf{\\rho_{\\mathbf{relative}}}$', \n",
    "           'Thermal Conductivity': r'$\\mathbf{\\sigma_{\\mathbf{t}}}$', \n",
    "           'SiC': r'$\\mathbf{C_{\\mathbf{SiC}}}$', \n",
    "           'ZrB2': r'$\\mathbf{C_{\\mathbf{ZrB2}}}$', \n",
    "           'Sinter temp': r'$\\mathbf{T_{\\mathbf{sinter}}}$'},\n",
    "    columns={'Relative Density': r'$\\mathbf{\\rho_{\\mathbf{relative}}}$', \n",
    "             'Thermal Conductivity': r'$\\mathbf{\\sigma_{\\mathbf{t}}}$', \n",
    "             'SiC': r'$\\mathbf{C_{\\mathbf{SiC}}}$', \n",
    "             'ZrB2': r'$\\mathbf{C_{\\mathbf{ZrB2}}}$', \n",
    "             'Sinter temp': r'$\\mathbf{T_{\\mathbf{sinter}}}$'}\n",
    ")\n",
    "\n",
    "# Draw the heatmap with increased font size for annotations and labels\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='plasma', vmin=-1, vmax=1,\n",
    "            annot_kws={\"size\": 28,\"weight\": \"bold\"},  # Annotation font size\n",
    "            cbar_kws={\"shrink\": 0.8})  # Color bar size \n",
    "# Customize the x and y labels with larger font\n",
    "cbar = plt.gca().collections[0].colorbar\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontsize(24)\n",
    "    label.set_fontweight('bold')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=32, weight='bold')\n",
    "plt.yticks(fontsize=32, weight='bold')\n",
    "\n",
    "# Add a title with increased font size\n",
    "plt.title('Pearson Correlation Matrix', fontsize=32,weight='bold')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with increased label size\n",
    "plt.savefig(\"Pearson_Correlation_Matrix_TC.png\", format='png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f59858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming filtered_df is your DataFrame\n",
    "x = df_raw[['ZrB2', 'SiC', 'Relative Density',\n",
    "       'Temp']]\n",
    "y = df_raw[['Thermal Conductivity']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming filtered_df is your DataFrame\n",
    "x = df_raw[['ZrB2', 'SiC', 'Relative Density',\n",
    "       'Temp']]\n",
    "y = df_raw['Thermal Conductivity']  # Changed to Series\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the training and testing data\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) for training and testing data\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Training Mean Squared Error:\", train_mse)\n",
    "print(\"Testing Mean Squared Error:\", test_mse)\n",
    "\n",
    "# Calculate the R² score for training and testing data\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"Training R^2 Score:\", train_r2)\n",
    "print(\"Testing R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (df_raw['Temp'] <= 100),\n",
    "    (df_raw['Temp'] > 100) & (df_raw['Temp'] <= 500),\n",
    "    (df_raw['Temp'] > 500) & (df_raw['Temp'] <= 1000),\n",
    "    (df_raw['Temp'] > 1000) & (df_raw['Temp'] <= 1500),\n",
    "    (df_raw['Temp'] > 1500)\n",
    "]\n",
    "\n",
    "labels = [0, 1,2, 3, 4]\n",
    "\n",
    "# Use np.select to assign the labels based on the conditions\n",
    "df_raw['Label'] = pd.Series(pd.NA, index=df_raw.index)  # Create an empty column 'Label'\n",
    "\n",
    "df_raw['Label'] = pd.Series(\n",
    "    pd.NA, dtype=pd.Int64Dtype(), index=df_raw.index\n",
    ") \n",
    "\n",
    "\n",
    "df_raw['Label'] = np.select(conditions, labels, default=df_raw['Label'])\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.groupby(['Label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing 'Label' values\n",
    "df_raw = df_raw.dropna(subset=['Label'])\n",
    "\n",
    "# Convert 'Label' column to integers\n",
    "df_raw['Label'] = df_raw['Label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0907b2",
   "metadata": {},
   "source": [
    "## Applying Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227f539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE,SMOTENC,SVMSMOTE,KMeansSMOTE\n",
    "ada = SVMSMOTE(random_state = 44, k_neighbors = 2)\n",
    "X_res, y_res = ada.fit_resample(df_raw.iloc[:,:-1], df_raw.iloc[:,-1])\n",
    "\n",
    "Ada_data = pd.concat([X_res, y_res], axis=1)\n",
    "Ada_data = Ada_data.drop_duplicates()\n",
    "Ada_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f921baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_data.groupby(['Label']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d325f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = Ada_data[['ZrB2', 'SiC', 'Sinter temp', 'Relative Density',\"Temp\"]]\n",
    "Y1 = Ada_data['Thermal Conductivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ada_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5742a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = Ada_data\n",
    "df_raw=df_raw.drop(['Label'],axis=1)\n",
    "train_dataset = df_raw.sample(frac=0.8, random_state=44)\n",
    "test_dataset = df_raw.drop(train_dataset.index)\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7193998",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset.pop('Thermal Conductivity') #y_train\n",
    "y_test = test_dataset.pop('Thermal Conductivity')   # y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757e510",
   "metadata": {},
   "source": [
    "## Trying ML different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caca178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "\n",
    "imptrain = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imptest = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "Train_scaler = MinMaxScaler()\n",
    "Test_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = Train_scaler.fit_transform(train_dataset)\n",
    "X_test_scaled = Test_scaler.fit_transform(test_dataset)\n",
    "\n",
    "imptrain.fit(X_train_scaled)\n",
    "imptest.fit(X_test_scaled)\n",
    "\n",
    "X_train_scaled = imptrain.transform(X_train_scaled)\n",
    "X_test_scaled = imptest.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def make_regression(X_train, y_train, X_test, y_test, model, model_name, verbose=True):\n",
    "    \"\"\"Apply selected regression model to data and measure error\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        #print(\"Train MAE = {:.4f} in {}\".format(train_mae, model_name))\n",
    "        # print(\"Train R^2 = {:.4f} in {}\".format(train_r2, model_name))\n",
    "        #print(\"Test MAE = {:.4f} in {}\".format(test_mae, model_name))\n",
    "        print(\".\".format(test_r2, model_name))\n",
    "        \n",
    "    return model, y_test_pred, train_mae, train_r2, test_mae, test_r2\n",
    "\n",
    "# Assuming you have a dictionary of regression models\n",
    "regression_models = {\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=44),\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=44),\n",
    "    \"XGBoost\": XGBRegressor(random_state=44),\n",
    "    \"KRR\": KernelRidge(),\n",
    "    \"ABR\": AdaBoostRegressor(random_state=44),\n",
    "    \"GBR\": GradientBoostingRegressor(random_state=44),\n",
    "    \"ETR\": ExtraTreesRegressor(random_state=44),\n",
    "    \"KNN\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Iterate over the dictionary of models\n",
    "for model_name, model in regression_models.items():\n",
    "    _, y_test_pred, train_mae, train_r2, test_mae, test_r2 = make_regression(X_train_scaled, y_train, X_test_scaled, y_test, model, model_name, verbose=True)\n",
    "    print(\"R2 of\", model_name, \"=\", test_r2)\n",
    "    print(\"MAE of\", model_name, \"=\", test_mae)\n",
    "    print(\"Train MAE of\", model_name, \"=\", train_mae)\n",
    "    print(\"Train R2 of\", model_name, \"=\", train_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regression(X_train, y_train, X_test, y_test, model, model_name, verbose=True):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_predict=model.predict(X_train)\n",
    "    train_error = mean_absolute_error(y_train, y_predict)\n",
    "    y_predict=model.predict(X_test)\n",
    "    test_error = mean_absolute_error(y_test, y_predict)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Train error = \"'{}'.format(train_error)+\" in \" + model_name)\n",
    "        print(\"Test error = \"'{}'.format(test_error)+\" in \" + model_name)\n",
    "    trained_model = model\n",
    "    \n",
    "    return trained_model, y_predict, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61733705",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    \"DecisionTree\" : DecisionTreeRegressor(random_state=44),\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\" : RandomForestRegressor(random_state=44),\n",
    "    \"XGBoost\": XGBRegressor(random_state=44),\n",
    "    \"KRR\":KernelRidge(),\n",
    "    \"ABR\": AdaBoostRegressor(random_state=44),\n",
    "    \"GBR\": GradientBoostingRegressor(random_state=44),\n",
    "    \"ETR\": ExtraTreesRegressor(random_state=44),\n",
    "    \"KNN\":KNeighborsRegressor()\n",
    "}\n",
    "for model_name in regression_models.keys():\n",
    "    _, y_predict, _, _= make_regression(X_train_scaled, y_train, X_test_scaled, y_test,regression_models[model_name], model_name, verbose=True)\n",
    "    print(\"R2 of\",model_name,\"=\", r2_score(y_test,y_predict),\"\\n\"),\n",
    "    print(\"MAE of\",model_name,\"=\", mean_absolute_error(y_test,y_predict),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Extra Trees Regressor\n",
    "extra_trees = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = extra_trees.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c7d68",
   "metadata": {},
   "source": [
    "## Final model for Thermal conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4780291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Extra Trees Regressor\n",
    "extra_trees = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = extra_trees.predict(X_test)\n",
    "y_pred_train = extra_trees.predict(X_train)\n",
    "\n",
    "# Calculate Mean Squared Error for testing set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Mean Squared Error (Test):\", mse_test)\n",
    "\n",
    "# Calculate Mean Absolute Error for testing set\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"Mean Absolute Error (Test):\", mae_test)\n",
    "\n",
    "# Calculate R² score for testing set\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(\"R² Score (Test):\", r2_test)\n",
    "\n",
    "# Calculate Mean Absolute Error for training set\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Mean Absolute Error (Train):\", mae_train)\n",
    "\n",
    "# Calculate R² score for training set\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(\"R² Score (Train):\", r2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X1 and Y1 are already defined as your features and target respectively\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Define the hyperparameter grid for SVR\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],  # I removed 'poly' and 'sigmoid' for now to simplify testing\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'epsilon': [0.01, 0.1, 0.5],  # Specifies the epsilon-tube\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf' and 'linear'\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (Test): {mse}\")\n",
    "print(f\"R^2 Score (Test): {r2_test}\")\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "r2_train = best_model.score(X_train, y_train)\n",
    "print(f\"R^2 Score (Train): {r2_train}\")\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Plotting True vs Predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "\n",
    "# Add a diagonal reference line (Perfect Prediction line)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"True_vs_Predicted_Values_SVR.png\", format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize the KFold cross-validation splitter\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(X1)):\n",
    "    print(f\"Fold {fold_idx + 1}/{num_folds}\")\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train, X_val = X1.iloc[train_index], X1.iloc[val_index]\n",
    "    y_train, y_val = Y1.iloc[train_index], Y1.iloc[val_index]\n",
    "   \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate evaluation metrics for this fold\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    # Append scores to lists\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    # Print evaluation metrics for this fold\n",
    "    print(f\"  Validation R^2: {r2:.4f}\")\n",
    "    print(f\"  Validation MSE: {mse:.4f}\")\n",
    "    print(f\"  Validation MAE: {mae:.4f}\")\n",
    "\n",
    "# Calculate the average scores across all folds\n",
    "average_mse = np.mean(mse_scores)\n",
    "average_mae = np.mean(mae_scores)\n",
    "average_r2 = np.mean(r2_scores)\n",
    "\n",
    "print(f\"\\nAverage Validation MSE: {average_mse:.4f}\")\n",
    "print(f\"Average Validation MAE: {average_mae:.4f}\")\n",
    "print(f\"Average Validation R^2: {average_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(best_model, X_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Summary plot (global interpretation)\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming X1 is your dataset and best_model is your trained model\n",
    "importances = best_model.feature_importances_\n",
    "features = pd.DataFrame({'Feature': X1.columns, 'Importance': importances})\n",
    "\n",
    "# Sort features by importance\n",
    "features = features.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=features, orient='h', palette='viridis')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "plt.savefig(\"Feature_Importances_TC.png\", format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "features = pd.DataFrame({'Feature': X1.columns, 'Importance': importances})\n",
    "\n",
    "# Sort features by importance\n",
    "features = features.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting feature importances using a swarm plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.swarmplot(x='Importance', y='Feature', data=features, palette='viridis')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "plt.savefig(\"Swarn_Plot_TC.png\", format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daed419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize the KFold cross-validation splitter\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "mse_scores = []\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(X1)):\n",
    "    print(f\"Fold {fold_idx + 1}/{num_folds}\")\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train, X_val = X1.iloc[train_index], X1.iloc[val_index]\n",
    "    y_train, y_val = Y1.iloc[train_index], Y1.iloc[val_index]\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Calculate R² score for training data\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    train_r2_scores.append(train_r2)\n",
    "   \n",
    "    \n",
    "    print(f\"  Training R^2: {train_r2:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Calculate the average R² score across all folds for training and validation data\n",
    "average_train_r2 = np.mean(train_r2_scores)\n",
    "print(f\"\\nAverage Training R²: {average_train_r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1e563",
   "metadata": {},
   "source": [
    "## Applying Model trained for thermal conductivity on cleaned oxide scale thickness dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b339a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('thermal_conductivity_vs_SiC_concentration_multiple_10.csv')\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d741bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a51cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testing = dataframe[['ZrB2', 'SiC', 'Sinter temp', 'Relative Density', 'Temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760524d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = best_model.predict(X_testing)\n",
    "dataframe[\"Thermal Conductivity\"] = y_prediction\n",
    "dataframe.to_csv('thermal_conductivity_vs_SiC_concentration.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot for the first segment (0-14)\n",
    "plt.scatter(dataframe['SiC'][0:15], dataframe['Thermal Conductivity'][0:15], color='yellow', alpha=0.5, label='2000')  \n",
    "\n",
    "# Scatter plot for the second segment (15-29)\n",
    "plt.scatter(dataframe['SiC'][15:30], dataframe['Thermal Conductivity'][15:30], color='red', alpha=0.5, label='1800')\n",
    "\n",
    "# Scatter plot for the third segment (30-44)\n",
    "plt.scatter(dataframe['SiC'][30:45], dataframe['Thermal Conductivity'][30:45], color='black', alpha=0.5, label='1600')\n",
    "\n",
    "# Scatter plot for the fourth segment (45-59)\n",
    "plt.scatter(dataframe['SiC'][45:60], dataframe['Thermal Conductivity'][45:60], color='grey', alpha=0.5, label='1400')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('SiC vs Thermal Conductivity at 1900 Celsius and 100 Percent Densification')  \n",
    "plt.xlabel('SiC Percent in ZrB2 Composite (%)') \n",
    "plt.ylabel('Thermal Conductivity (W/mK)')  \n",
    "\n",
    "# Add grid\n",
    "plt.grid(True) \n",
    "\n",
    "# Add legend to distinguish the segments\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()  \n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('SiC_conc_vs_Thermal_Conductivity.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe.iloc[59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe=pd.read_csv(\"Completed_maybe.csv\")\n",
    "print(Dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208da3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe\n",
    "Dataframe = Dataframe.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testin = Dataframe[['ZrB2', 'SiC', 'Sinter temp', 'Relative Density', 'Temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictio = best_model.predict(X_testin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2605825",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe[\"Thermal Conductivity\"] = y_predictio\n",
    "Dataframe\n",
    "Dataframe.to_csv('Oxidation_ZrB2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dc220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99622ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d2b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
